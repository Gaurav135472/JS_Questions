{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "from bs4 import BeautifulSoup\n",
    "import lxml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You are given a SQL file link: https://drive.google.com/file/d/1WFt7B84LTHhMueoKmz8W-PRo7xXqmZf3/view?usp=share_link. Read the data by using the file and store it in a excel file. In this data, there are 3 tables named \"invoices\", \"order_leads\" and \"sales_sql\". So create 3 sheets to your excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mysql.connector\n",
    "# import pandas as pd\n",
    "\n",
    "# conn = mysql.connector.connect(\n",
    "#     host='localhost',\n",
    "#     user='root',\n",
    "#     password='',\n",
    "#     database='temp_db2'\n",
    "# )\n",
    "\n",
    "# invoices = pd.read_sql_query('SELECT * FROM invoices', conn)\n",
    "# order_leads = pd.read_sql_query('SELECT * FROM invoices order_leads', conn)\n",
    "# sales_sql = pd.read_sql_query('SELECT * FROM invoices sales_sql', conn)\n",
    "\n",
    "# with pd.ExcelWriter('output2.xlsx') as writer:\n",
    "#     invoices.to_excel(writer, sheet_name='invoices')\n",
    "#     order_leads.to_excel(writer, sheet_name='order_leads')\n",
    "#     sales_sql.to_excel(writer, sheet_name='sales_sql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to the site: https://rapidapi.com/wirefreethought/api/geodb-cities. From here, you have to grab the API and have to choose proper routes to get the cities of different countries. After getting the right API, hit that API and create a dataframe of all the cities that you can get by using the API. Then store the dataframe to a SQL. If you need to create an account or have to subscribe, then do that (it has free subscription but has some limitations. Use that free subscription and modify your accordingly to get all the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pymysql\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "# url = 'https://wft-geo-db.p.rapidapi.com/v1/geo/cities'\n",
    "\n",
    "# headers = {\n",
    "#     'x-rapidapi-host': 'wft-geo-db.p.rapidapi.com',\n",
    "#     'x-rapidapi-key': '53a59b9d19msh4863b1a86f981eep1f3eaajsn53846823fe6b'  # Replace with your actual API key\n",
    "# }\n",
    "\n",
    "# response = requests.get(url, headers=headers)\n",
    "\n",
    "# data = response.json()\n",
    "# df = pd.DataFrame(data['data'])\n",
    "\n",
    "# engine = create_engine('mysql+pymysql://root@localhost/temp_db')\n",
    "\n",
    "# df.to_sql('api', con = engine, if_exists='append')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go to this url: https://www.flipkart.com/search?q=smartphones. This is the url to find phones in flipkart website. You have to extract the below things:\n",
    "\n",
    "# image url of the phone\n",
    "# name of the image\n",
    "# average ratings\n",
    "# total ratings\n",
    "# total reviews\n",
    "# discounted price\n",
    "# actual price\n",
    "# Extract all the phones which are available in this website. So you have to use the pagination concept. Also after requesting every page through the url, please wait for a while (minimum 2-3 seconds), otherwise your IP address can be banned to access the flipkart website later.\n",
    "\n",
    "# After collecting all the data, save that in a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# webpage = requests.get('https://www.flipkart.com/search?q=smartphones').text\n",
    "# soup = BeautifulSoup(webpage, 'lxml')\n",
    "\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lxml imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# webpage = requests.get('https://www.flipkart.com/search?q=smartphones').text\n",
    "# soup = BeautifulSoup(webpage, 'lxml')\n",
    "\n",
    "\n",
    "# print(soup.prettify())\n",
    "\n",
    "import lxml\n",
    "print(\"lxml imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4205356249.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[46], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    python -m pip show lxml\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.12.5 (tags/v3.12.5:ff3bc82, Aug  6 2024, 20:45:27) [MSC v.1940 64 bit (AMD64)]\n",
      "lxml version: 5.3.0\n"
     ]
    },
    {
     "ename": "FeatureNotFound",
     "evalue": "Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFeatureNotFound\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlxml version:\u001b[39m\u001b[38;5;124m\"\u001b[39m, lxml\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m      9\u001b[0m webpage \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.flipkart.com/search?q=smartphones\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m---> 10\u001b[0m soup \u001b[38;5;241m=\u001b[39m \u001b[43mBeautifulSoup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwebpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlxml\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(soup\u001b[38;5;241m.\u001b[39mprettify())\n",
      "File \u001b[1;32mc:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\bs4\\__init__.py:250\u001b[0m, in \u001b[0;36mBeautifulSoup.__init__\u001b[1;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, element_classes, **kwargs)\u001b[0m\n\u001b[0;32m    248\u001b[0m     builder_class \u001b[38;5;241m=\u001b[39m builder_registry\u001b[38;5;241m.\u001b[39mlookup(\u001b[38;5;241m*\u001b[39mfeatures)\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m builder_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m FeatureNotFound(\n\u001b[0;32m    251\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a tree builder with the features you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequested: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m. Do you need to install a parser library?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(features))\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# At this point either we have a TreeBuilder instance in\u001b[39;00m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# builder, or we have a builder_class that we can instantiate\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# with the remaining **kwargs.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m builder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mFeatureNotFound\u001b[0m: Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import lxml\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "print(\"Python version:\", sys.version)\n",
    "print(\"lxml version:\", lxml.__version__)\n",
    "\n",
    "webpage = requests.get('https://www.flipkart.com/search?q=smartphones').text\n",
    "soup = BeautifulSoup(webpage, 'lxml')\n",
    "print(soup.prettify())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lxml\n"
     ]
    }
   ],
   "source": [
    "import lxml\n",
    "import os\n",
    "print(os.path.dirname(lxml.__file__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\python312.zip', 'c:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\DLLs', 'c:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib', 'c:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312', '', 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages', 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\win32', 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\User\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'BeautifulSoup' has no attribute 'builder_registry'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m webpage \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://www.flipkart.com/search?q=smartphones\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Check available parsers\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAvailable parsers:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mBeautifulSoup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder_registry\u001b[49m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Attempt initialization with 'lxml'\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: type object 'BeautifulSoup' has no attribute 'builder_registry'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "webpage = requests.get('https://www.flipkart.com/search?q=smartphones').text\n",
    "\n",
    "# Check available parsers\n",
    "print(\"Available parsers:\", BeautifulSoup.builder_registry)\n",
    "\n",
    "# Attempt initialization with 'lxml'\n",
    "try:\n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "    print(\"BeautifulSoup initialized with 'lxml'\")\n",
    "except Exception as e:\n",
    "    print(\"Error initializing BeautifulSoup with 'lxml':\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error initializing BeautifulSoup with 'lxml': Couldn't find a tree builder with the features you requested: lxml. Do you need to install a parser library?\n",
      "BeautifulSoup initialized with 'html.parser'\n",
      "Error initializing BeautifulSoup with 'html5lib': Couldn't find a tree builder with the features you requested: html5lib. Do you need to install a parser library?\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "webpage = requests.get('https://www.flipkart.com/search?q=smartphones').text\n",
    "\n",
    "# Print available parsers by attempting to initialize with each\n",
    "parsers = ['lxml', 'html.parser', 'html5lib']\n",
    "for parser in parsers:\n",
    "    try:\n",
    "        soup = BeautifulSoup(webpage, parser)\n",
    "        print(f\"BeautifulSoup initialized with '{parser}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing BeautifulSoup with '{parser}': {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
